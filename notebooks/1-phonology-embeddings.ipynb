{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fix_notebook_imports\n",
    "\n",
    "from src import util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipa_pickle_path = os.path.join(util.DATA_RAW_DIR, \"IPA_DF.pkl\")\n",
    "df_annotated_csv_path = os.path.join(util.DATA_RAW_DIR, \"annotated_feature_DF.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_ipa_pickle_path, 'rb') as f:\n",
    "    df_ipa = pickle.load(f)\n",
    "    \n",
    "df_ipa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated = pd.read_csv(df_annotated_csv_path)\n",
    "df_annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-binary columns\n",
    "drop_columns = [\"cont\"]\n",
    "\n",
    "df_annotated = df_annotated.drop(columns=drop_columns)\n",
    "df_annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(x) for x in df_annotated[\"phoneme\"]])\n",
    "\n",
    "def get_phonemes(s, phonemes_set):\n",
    "    phonemes = []\n",
    "        \n",
    "    s = s.replace(\" \", \"\")\n",
    "    while 1:\n",
    "        phoneme_found = False\n",
    "        for length in range(max_length, 0, -1):\n",
    "            phoneme = s[:length]\n",
    "            if phoneme in phonemes_set: \n",
    "                phoneme_found = True\n",
    "                phonemes.append(phoneme)\n",
    "        \n",
    "        if phoneme_found == \"\":\n",
    "            s = s[len(phoneme):]\n",
    "        else:\n",
    "            s = s[1:]            \n",
    "        \n",
    "        if len(s) == 0:\n",
    "            return phonemes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_phonemes_list = []\n",
    "\n",
    "phonemes_set = set([row[\"phoneme\"] for index, row in df_annotated.iterrows()])\n",
    "\n",
    "for index, row in df_ipa.iterrows():\n",
    "    language = row[1]\n",
    "    s = row[3]\n",
    "    phonemes = get_phonemes(s, phonemes_set)\n",
    "    language_phonemes_list.append((language, phonemes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phonemes = pd.DataFrame(data=language_phonemes_list, columns=(\"language\", \"transcription_ipa_phonemes\"))\n",
    "df_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_to_name_dict = {row[\"phoneme\"] : row[\"name\"] for index, row in df_annotated.iterrows()}\n",
    "\n",
    "df_phonemes[\"transcription_ipa_names\"] = df_phonemes[\"transcription_ipa_phonemes\"].apply(lambda x: [phoneme_to_name_dict[phoneme] for phoneme in x])\n",
    "df_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in np.unique(df_phonemes[\"language\"]):\n",
    "    count = len(df_phonemes[df_phonemes[\"language\"] == language])\n",
    "    print(f\"{language}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_rename_mapper = {language : language.replace(\"-tok\", \"\") for language in list(set(df_phonemes[\"language\"]))}\n",
    "\n",
    "df_phonemes[\"language\"] = df_phonemes[\"language\"].replace(language_rename_mapper)\n",
    "df_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_languages = list(set(df_phonemes[\"language\"]))\n",
    "unique_languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = []\n",
    "for phonemes_list in df_phonemes[\"transcription_ipa_phonemes\"]:\n",
    "    phonemes += list(phonemes_list)\n",
    "    \n",
    "unique_phonemes = list(set(phonemes))\n",
    "\n",
    "len(unique_phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_to_phonemes_dict_temp = defaultdict(list)\n",
    "\n",
    "for index, row in df_phonemes.iterrows():\n",
    "    language_to_phonemes_dict_temp[row[\"language\"]] += row[\"transcription_ipa_phonemes\"]\n",
    "    \n",
    "language_to_phonemes_dict = {}\n",
    "for language, phonemes in language_to_phonemes_dict_temp.items():\n",
    "    language_to_phonemes_dict[language] = sorted(list(set(phonemes)))\n",
    "    \n",
    "del language_to_phonemes_dict_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phonetic_features = np.array(df_annotated.columns[3:])\n",
    "\n",
    "DIM = len(unique_phonetic_features)\n",
    "\n",
    "def get_phoneme_to_phonetic_features_dict():\n",
    "    phoneme_to_phonetic_features_dict = defaultdict(list)\n",
    "    for phoneme in unique_phonemes:\n",
    "        mask = np.array(df_annotated[df_annotated[\"phoneme\"] == phoneme].iloc[0, 3:]).astype(bool) # produces a mask since values are binary\n",
    "        phoneme_to_phonetic_features_dict[phoneme] = unique_phonetic_features[mask] \n",
    "        \n",
    "    return phoneme_to_phonetic_features_dict\n",
    "\n",
    "phoneme_to_phonetic_features_dict = get_phoneme_to_phonetic_features_dict()\n",
    "phoneme_to_phonetic_features_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(n):\n",
    "    return itertools.combinations(unique_phonetic_features, n)\n",
    "\n",
    "def get_phoneme_to_phonetic_feature_n_grams_dict(max_n):\n",
    "    assert type(max_n) == int\n",
    "    assert max_n >= 1\n",
    "    \n",
    "    phoneme_to_phonetic_feature_n_grams_dict = defaultdict(list)\n",
    "    \n",
    "    for phoneme in unique_phonemes:\n",
    "        for n in range(1, max_n+1):\n",
    "            n_grams = get_n_grams(n)\n",
    "            for n_gram in n_grams:\n",
    "                if set(n_gram).issubset(set(phoneme_to_phonetic_features_dict[phoneme])):\n",
    "                    phoneme_to_phonetic_feature_n_grams_dict[phoneme].append(n_gram)\n",
    "    \n",
    "    return phoneme_to_phonetic_feature_n_grams_dict\n",
    "\n",
    "phoneme_to_phonetic_feature_n_grams_dict = get_phoneme_to_phonetic_feature_n_grams_dict(max_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams_pool = set(itertools.chain.from_iterable(phoneme_to_phonetic_feature_n_grams_dict.values()))\n",
    "len(n_grams_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_n_grams_in_range_in_pool(max_n, min_n=1):\n",
    "    assert type(max_n) == int\n",
    "    assert max_n >= min_n\n",
    "    \n",
    "    n_grams = []\n",
    "    for n in range(min_n, max_n+1):\n",
    "        n_grams += get_n_grams(n)\n",
    "        \n",
    "    n_grams = [n_gram for n_gram in n_grams if n_gram in n_grams_pool]\n",
    "        \n",
    "    return np.array(n_grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_phoneme(phoneme, n_grams):\n",
    "    return np.array([ 1 if n_gram in phoneme_to_phonetic_feature_n_grams_dict[phoneme] else 0 for n_gram in n_grams ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_for_language(language, n_grams):\n",
    "    feat = np.zeros((len(n_grams),))\n",
    "    \n",
    "    phonemes = language_to_phonemes_dict[language]\n",
    "    phonemes = list(set(phonemes))\n",
    "    for phoneme in phonemes:\n",
    "        feat = feat + get_features_for_phoneme(phoneme, n_grams)\n",
    "        \n",
    "    feat = feat / len(phonemes) # normalize for different numbers of phonemes\n",
    "             \n",
    "    return feat \n",
    "    \n",
    "\n",
    "def get_feature_matrix(n_grams):\n",
    "    \n",
    "    m = len(unique_languages)\n",
    "    n = len(n_grams)\n",
    "    print(m, n)\n",
    "    \n",
    "    feature_matrix = np.zeros((m, n))\n",
    "    for i, language in enumerate(unique_languages):\n",
    "        feature_matrix[i, :] = get_features_for_language(language, n_grams)\n",
    "    \n",
    "    df = pd.DataFrame(feature_matrix)\n",
    "    feat_avg = df.mean(axis=0)\n",
    "    feat_std = df.std(axis=0)\n",
    "\n",
    "    for i in range(m):\n",
    "        feat = feature_matrix[i, :]\n",
    "        feat  = (feat - feat_avg) / feat_std\n",
    "        feature_matrix[i, :] = feat\n",
    "        \n",
    "    return feature_matrix\n",
    "\n",
    "n_grams = get_all_n_grams_in_range_in_pool(max_n=3, min_n=2)\n",
    "feature_matrix = get_feature_matrix(n_grams)\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings_2D(df_embedded, title, method, figsize=(10,6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"dim_1\", \n",
    "        y=\"dim_2\", \n",
    "        data=df_embedded\n",
    "    )\n",
    "\n",
    "    plt.title(f'{title}, Method: {method})')\n",
    "\n",
    "    def label_point(x, y, val, ax):\n",
    "        a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "        for i, point in a.iterrows():\n",
    "            ax.text(point['x']+.02, point['y'], str(point['val']))\n",
    "\n",
    "    label_point(df_embedded.dim_1, df_embedded.dim_2, df_embedded.language, plt.gca())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings_3D(df_embedded, title, method, figsize=(10,6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(\n",
    "        df_embedded[\"dim_1\"],\n",
    "        df_embedded[\"dim_2\"],\n",
    "        df_embedded[\"dim_3\"],\n",
    "    )\n",
    "\n",
    "    plt.title(f'{title}, Method: {method})')\n",
    "\n",
    "    def label_point(x, y, z, val, ax):\n",
    "        a = pd.concat({'x': x, 'y': y, 'z': z, 'val': val}, axis=1)\n",
    "        for i, point in a.iterrows():\n",
    "            ax.text(point['x']+.02, point['y'], point['z'], str(point['val']))\n",
    "\n",
    "    label_point(df_embedded.dim_1, df_embedded.dim_2, df_embedded.dim_3, df_embedded.language, plt.gca())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA \n",
    "\n",
    "NUM_PC = 3\n",
    "\n",
    "pca = PCA()\n",
    "X_embedded = pca.fit_transform(feature_matrix)\n",
    "df_pca = pd.DataFrame(X_embedded[:,:NUM_PC], columns=[f\"dim_{i}\" for i in range(1, NUM_PC+1)])\n",
    "df_pca[\"language\"] = unique_languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D PCA\n",
    "\n",
    "plot_embeddings_2D(df_pca, title=\"Phonology Embeddings\", method=\"PCA\", figsize=(5,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3D PCA\n",
    "\n",
    "plot_embeddings_3D(df_pca, title=\"Phonology Embeddings\", method=\"PCA\", figsize=(6,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE\n",
    "\n",
    "tsne_2D = TSNE(n_components=2, perplexity=10, learning_rate=100)\n",
    "X_embedded_2D = tsne_2D.fit_transform(feature_matrix)\n",
    "df_tsne_2D = pd.DataFrame(X_embedded_2D, columns=[\"dim_1\", \"dim_2\"])\n",
    "df_tsne_2D[\"language\"] = unique_languages\n",
    "plot_embeddings_2D(df_tsne_2D, title=\"Phonology Embeddings\", method=\"t-SNE\", figsize=(5,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
